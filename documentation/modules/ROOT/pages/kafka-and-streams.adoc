= Apache Kafka with Reactive Streams

Mutiny is just part of the Reactive story. To complement it, we need Reactive Streams too. And an important service that can serve as the underlying implementation for our stream is http://kafka.apache.org[Apache Kafka,window=_blank].

In this chapter we're going to use Mutiny to create price request for wines to a remote service called `price-generator` using Kafka as the broker for our messages in a Kafka topic called `wine`. The `price-generator` will get the wine from this topic, add a tag price to it, and send the information back in a Kafka topic called `priced-wine`. Finally, we'll read the priced wines from the topic and send it throught our REST endpoint using SSE (Server-Side Events).

== Add the Reactive Messaging Kafka extension

Just open a new terminal window, and make sure youâ€™re at the root of your `{project-name}` project, then run:

[.console-input]
[source,bash]
----
./mvnw quarkus:add-extension -Dextensions="io.quarkus:quarkus-smallrye-reactive-messaging-kafka"
----

== Create Wine POJO

Create a new `Wine` Java class in `src/main/java` in the `com.redhat.developers` package with the following contents:

[.console-input]
[source,java]
----
package com.redhat.developers;

import java.math.BigDecimal;

public class Wine {
   
    private String name;

    private Wine(String name) {
        this.name = name;
    }

    public static Wine of(String name) {
        return new Wine(name);
    }
    
    public PricedWine withPrice(BigDecimal price) {
        return PricedWine.of(this.name, price);
    }

    public String getName() {
        return name;
    }
    
}
----

== Create PricedWine POJO

Create a new `PricedWine` Java class in `src/main/java` in the `com.redhat.developers` package with the following contents:

[.console-input]
[source,java]
----
package com.redhat.developers;

import java.math.BigDecimal;

import javax.json.bind.annotation.JsonbCreator;

public class PricedWine {

    private String name;

    private BigDecimal price;

    private PricedWine(String name, BigDecimal price) {
        this.name = name;
        this.price = price;
    }

    @JsonbCreator
    public static PricedWine of(String name, double price) {
        return new PricedWine(name, new BigDecimal(price).setScale(2));
    }

    public static PricedWine of(String name, BigDecimal price) {
        return new PricedWine(name, price);
    }

    public String getName() {
        return name;
    }

    public BigDecimal getPrice() {
        return price;
    }

}
----

== Create WineGenerator

Create a new `WineGenerator` Java class in `src/main/java` in the `com.redhat.developers` package with the following contents:

[.console-input]
[source,java]
----
package com.redhat.developers;

import java.time.Duration;
import java.util.Arrays;
import java.util.List;
import java.util.concurrent.ThreadLocalRandom;
import java.util.stream.Collectors;

import javax.enterprise.context.ApplicationScoped;
import javax.json.bind.JsonbBuilder;

import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.smallrye.mutiny.Multi;

@ApplicationScoped
public class WineGenerator {

    private static final List<Wine> WINES = 
        Arrays.asList("Fay", "Cask 23", "Jordan", "Caymus", "Don Melchor", "Barca Velha", "Pera Manca")
            .stream().map(Wine::of).collect(Collectors.toList());

    @Outgoing("wine")
    Multi<String> wines() {
        return Multi.createFrom().ticks().every(Duration.ofSeconds(1)) <1>
        .onOverflow().drop() <2>
        .map(tick -> WINES.get(ThreadLocalRandom.current().nextInt(0, WINES.size()))) <3>
        .map(JsonbBuilder.create()::toJson); <4>
    }

}
----
<1> We're creating a Multi that generates a new message every `1` second.
<2> We apply backpressure by dropping the messages if the topic is not ready.
<3> For each message we choose a random `Wine` from our list.
<4> We map the `Wine` to JSON format.

== Create WineResource

Create a new `WineResource` Java class in `src/main/java` in the `com.redhat.developers` package with the following contents:

[.console-input]
[source,java]
----
package com.redhat.developers;

import javax.json.bind.JsonbBuilder;
import javax.ws.rs.GET;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;

import org.eclipse.microprofile.reactive.messaging.Channel;
import org.jboss.resteasy.annotations.SseElementType;

import io.smallrye.mutiny.Multi;

@Path("/wine")
public class WineResource {
    
    @Channel("priced-wine") <1>
    Multi<String> pricedWines;

    @GET
    @Produces(MediaType.SERVER_SENT_EVENTS)
    @SseElementType(MediaType.APPLICATION_JSON)
    public Multi<PricedWine> wines() {
        return pricedWines.map(s -> JsonbBuilder.create().fromJson(s, PricedWine.class)); <2>
    }

}
----
<1> We inject the Multi directly by using the `@Channel` annotation.
<2> We just map the `PricedWine` to JSON format.

== Add the Reactive Messaging Kafka properties

Add the following properties to your `application.properties` in `src/main/resources`:

[.console-input]
[source,properties]
----
mp.messaging.incoming.priced-wine.connector=smallrye-kafka
mp.messaging.incoming.priced-wine.topic=priced-wine
mp.messaging.incoming.priced-wine.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

mp.messaging.outgoing.wine.connector=smallrye-kafka
mp.messaging.outgoing.wine.topic=wine
mp.messaging.outgoing.wine.value.serializer=org.apache.kafka.common.serialization.StringSerializer
----

== Create docker-compose configuration

The external dependencies required to run this chapter are:

- Kafka
- Zookeeper (required by Kafka)
- The `price-generator` service

We're going to use `docker-compose` to bootstrap these external services.

Create a new file called `docker-compose.yml` in the root of your `{project-name}` folder:

[.console-input]
[source,yaml]
----
version: '3'
services:
  zookeeper:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
      "sh", "-c",
      "bin/zookeeper-server-start.sh config/zookeeper.properties"
    ]
    ports:
      - "2181:2181"
    environment:
      LOG_DIR: /tmp/logs
  kafka:
    image: strimzi/kafka:0.11.3-kafka-2.1.0
    command: [
      "sh", "-c",
      "bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}"
    ]
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      LOG_DIR: "/tmp/logs"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  price-generator:
    image: quay.io/rhdevelopers/quarkus-tutorial-price-generator:1.0
    network_mode: host
    depends_on:
      - kafka
----

== Run docker-compose

Make sure you are in the same folder that you've created the `docker-compose.yml` file (in our case, the root of our `{project-name}` folder).
[.console-input]
[source,bash]
----
docker-compose up
----

[.console-output]
[source,text]
----
kafka_1            | [2020-05-13 01:54:53,281] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1            | [2020-05-13 01:54:53,281] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1            | [2020-05-13 01:54:53,284] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafka_1            | [2020-05-13 01:54:53,367] INFO Loading logs. (kafka.log.LogManager)
kafka_1            | [2020-05-13 01:54:53,504] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 15 with message format version 2 (kafka.log.Log)
kafka_1            | [2020-05-13 01:54:53,531] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file '/tmp/kafka-logs/__consumer_offsets-38/00000000000000000015.snapshot' (kafka.log.ProducerStateManager)
kafka_1            | [2020-05-13 01:54:53,550] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 15 in 125 ms (kafka.log.Log)
----

== Invoke the /wine endpoint

Run the following command:

[.console-input]
[source,bash]
----
curl -N localhost:8080/wine
----

[.console-output]
[source,text]
----
data: {"name":"Don Melchor","price":1921.00}

data: {"name":"Jordan","price":546.00}

data: {"name":"Cask 23","price":1089.00}

data: {"name":"Barca Velha","price":1855.00}

data: {"name":"Don Melchor","price":272.00}

data: {"name":"Cask 23","price":1500.00}

data: {"name":"Caymus","price":275.00}

data: {"name":"Cask 23","price":1084.00}

data: {"name":"Fay","price":1547.00}

data: {"name":"Jordan","price":917.00}

data: {"name":"Jordan","price":1090.00}

data: {"name":"Jordan","price":235.00}

data: {"name":"Don Melchor","price":1468.00}

data: {"name":"Pera Manca","price":1534.00}

data: {"name":"Barca Velha","price":316.00}
----

== Dev Services for Kafka

Because starting a Kafka broker can be long and you need to develop fast in your local environment, Dev Services for Kafka is here to help you!

Since `quarkus-smallrye-reactive-messaging-kafka` extension is present, Dev Services for Kafka automatically starts a Kafka broker in dev mode and when running tests.

TIP: You can disable Dev Services for Kafka by adding `quarkus.kafka.devservices.enabled=false` or configuring `kafka.bootstrap.servers` in `application.properties`.
